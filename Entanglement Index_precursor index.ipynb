{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bcb530-57d4-4099-8e19-24794df15660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7efc2cceda42159113a2266020d985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Enter Excel path, select conditions, wavelet, lag (0 = synchronous, >0 = precursor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Entanglement Index Calculator - Lagged EI for Future State Version (Fixed)\n",
    "# =============================================================================\n",
    "# Features:\n",
    "# - Loads Event A, B, optional Event C from Excel\n",
    "# - Computes ALL pairwise with full metrics (original, smoothed, normalized, weighted, resonant, symmetric, kernelized, discord)\n",
    "# - Computes 3-way interaction I(A;B;C) if Event C present\n",
    "# - Lagged EI for precursors: shift non-target events backward by lag (default 1 day) relative to target event\n",
    "# - Precursor significance: bootstrap CI + p-value for Original E > 0 on lagged pairs\n",
    "# - Adaptive decay, multi-scale wavelet spectrum + plot\n",
    "# - Bootstrap CI on original for all pairs\n",
    "# - User-adjustable Excel path, conditions, wavelet family, lag, target event\n",
    "#\n",
    "# Dependencies: pywavelets, scikit-learn, pandas, numpy, scipy, matplotlib, ipywidgets\n",
    "# Install if needed: !pip install pywavelets scikit-learn\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from typing import Union, Tuple, Optional, Callable, List, Dict\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "DEFAULT_EXCEL_PATH = r\"C:\\Users\\oliva\\OneDrive\\Documents\\Excel doc\\BTC.xlsx\"\n",
    "\n",
    "def load_events_from_excel(path: str = DEFAULT_EXCEL_PATH) -> Dict[str, pd.Series]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Excel file not found: {path}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading Excel: {str(e)}\")\n",
    "\n",
    "    if \"Time\" in df.columns:\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors='coerce')\n",
    "        df = df.sort_values(\"Time\").reset_index(drop=True)\n",
    "        print(\"Data sorted by 'Time'.\")\n",
    "\n",
    "    event_cols = [col for col in df.columns if col.startswith(\"Event \")]\n",
    "    if len(event_cols) < 2:\n",
    "        raise ValueError(\"Excel must have at least 'Event A' and 'Event B'.\")\n",
    "\n",
    "    events = {col: df[col] for col in event_cols}\n",
    "\n",
    "    print(f\"Loaded {len(df)} rows from {path}\")\n",
    "    for name, s in events.items():\n",
    "        print(f\"{name} range: {s.min():.2f} to {s.max():.2f}\")\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def define_event_series(\n",
    "    data: Union[list, np.ndarray, pd.Series],\n",
    "    event_condition: Union[str, float, Callable, None] = None\n",
    ") -> pd.Series:\n",
    "    if isinstance(data, (list, np.ndarray)):\n",
    "        s = pd.Series(data)\n",
    "    elif isinstance(data, pd.Series):\n",
    "        s = data.copy()\n",
    "    else:\n",
    "        raise ValueError(\"Input data must be list, numpy array or pandas Series\")\n",
    "    \n",
    "    s = s.dropna().reset_index(drop=True)\n",
    "    \n",
    "    if event_condition is None:\n",
    "        if s.dtype == bool:\n",
    "            return s.astype(int)\n",
    "        try:\n",
    "            return (s.astype(bool)).astype(int)\n",
    "        except:\n",
    "            raise ValueError(\"Cannot interpret data as boolean automatically. Provide event_condition.\")\n",
    "    \n",
    "    elif isinstance(event_condition, (int, float)):\n",
    "        return (s >= event_condition).astype(int)\n",
    "    \n",
    "    elif isinstance(event_condition, str):\n",
    "        cond = event_condition.lower()\n",
    "        if cond == 'positive':\n",
    "            return (s > 0).astype(int)\n",
    "        elif cond == 'negative':\n",
    "            return (s < 0).astype(int)\n",
    "        elif cond == 'nonzero':\n",
    "            return (s != 0).astype(int)\n",
    "        elif cond == 'above_mean':\n",
    "            return (s > s.mean()).astype(int)\n",
    "        elif cond == 'above_median':\n",
    "            return (s > s.median()).astype(int)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown string condition: {event_condition}\")\n",
    "    \n",
    "    elif callable(event_condition):\n",
    "        result = event_condition(s)\n",
    "        if not np.issubdtype(result.dtype, np.bool_):\n",
    "            raise ValueError(\"Custom function must return boolean Series\")\n",
    "        return result.astype(int)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"event_condition must be None, number, string preset or callable\")\n",
    "\n",
    "\n",
    "def find_optimal_decay_lambda(\n",
    "    A: np.ndarray,\n",
    "    B: np.ndarray,\n",
    "    alphas: List[float] = [0.5, 1.0],\n",
    "    n_splits: int = 5,\n",
    "    lambda_grid: np.ndarray = np.linspace(0.8, 1.0, 11),\n",
    "    base: float = 2\n",
    ") -> Tuple[float, float]:\n",
    "    n = len(A)\n",
    "    if n < 10:\n",
    "        return 0.95, 0.0\n",
    "\n",
    "    best_lambda = 0.95\n",
    "    best_score = -np.inf\n",
    "\n",
    "    fold_size = max(1, n // (n_splits + 1))\n",
    "    for lam in lambda_grid:\n",
    "        scores = []\n",
    "        for i in range(n_splits):\n",
    "            train_end = (i + 1) * fold_size\n",
    "            val_start = train_end\n",
    "            val_end = min(val_start + fold_size, n)\n",
    "\n",
    "            if val_end <= val_start:\n",
    "                continue\n",
    "\n",
    "            A_train, B_train = A[:train_end], B[:train_end]\n",
    "            A_val, B_val = A[val_start:val_end], B[val_start:val_end]\n",
    "\n",
    "            t_train = np.arange(len(A_train))\n",
    "            weights_train = lam ** (len(A_train) - 1 - t_train)\n",
    "            w_sum_train = weights_train.sum()\n",
    "            w_A_train = np.sum(weights_train * A_train)\n",
    "            w_B_train = np.sum(weights_train * B_train)\n",
    "            w_AB_train = np.sum(weights_train * (A_train & B_train))\n",
    "\n",
    "            p_B_train = (w_B_train + alphas[0]) / (w_sum_train + 2 * alphas[0])\n",
    "            p_B_given_A_train = (w_AB_train + alphas[0]) / (w_A_train + alphas[0] + alphas[1]) if w_A_train > 0 else alphas[0] / w_sum_train\n",
    "\n",
    "            ll = 0\n",
    "            n_val = len(A_val)\n",
    "            for a, b in zip(A_val, B_val):\n",
    "                if a == 1:\n",
    "                    prob = p_B_given_A_train if b == 1 else (1 - p_B_given_A_train)\n",
    "                else:\n",
    "                    prob = p_B_train if b == 1 else (1 - p_B_train)\n",
    "                ll += np.log(prob + 1e-10)\n",
    "\n",
    "            scores.append(ll / n_val if n_val > 0 else 0)\n",
    "\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_lambda = lam\n",
    "\n",
    "    return best_lambda, best_score\n",
    "\n",
    "\n",
    "def compute_multi_scale_rei(\n",
    "    A: np.ndarray,\n",
    "    B: np.ndarray,\n",
    "    scales: List[int] = [1, 2, 4, 8],\n",
    "    decay_lambda: float = 0.95,\n",
    "    alpha_joint: float = 0.5,\n",
    "    alpha_non: float = 1.0,\n",
    "    base: float = 2,\n",
    "    wavelet_family: str = 'haar'\n",
    ") -> Dict[str, Union[Dict[str, float], float]]:\n",
    "    spectrum = {}\n",
    "    avg_rei = 0.0\n",
    "    n_scales = 0\n",
    "\n",
    "    for scale in scales:\n",
    "        if scale > len(A) // 2:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            coeffs_A = pywt.wavedec(A, wavelet_family, level=scale)\n",
    "            coeffs_B = pywt.wavedec(B, wavelet_family, level=scale)\n",
    "            detail_A = coeffs_A[-1][:min(len(coeffs_A[-1]), len(coeffs_B[-1]))] if len(coeffs_A) > 1 else A\n",
    "            detail_B = coeffs_B[-1][:len(detail_A)] if len(coeffs_B) > 1 else B\n",
    "        except Exception as e:\n",
    "            print(f\"Wavelet decomposition failed at scale {scale}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if len(detail_A) < 5:\n",
    "            continue\n",
    "\n",
    "        detail_A_bin = (detail_A > 0).astype(int)\n",
    "        detail_B_bin = (detail_B > 0).astype(int)\n",
    "\n",
    "        t = np.arange(len(detail_A_bin))\n",
    "        weights = decay_lambda ** (len(detail_A_bin) - 1 - t)\n",
    "        w_sum = weights.sum()\n",
    "        w_A = np.sum(weights * detail_A_bin)\n",
    "        w_B = np.sum(weights * detail_B_bin)\n",
    "        w_AB = np.sum(weights * (detail_A_bin & detail_B_bin))\n",
    "\n",
    "        p_B_rei = (w_B + alpha_joint) / (w_sum + 2 * alpha_joint)\n",
    "        p_B_given_A_rei = (w_AB + alpha_joint) / (w_A + alpha_joint + alpha_non) if w_A > 0 else alpha_joint / (w_sum + 2 * alpha_joint)\n",
    "\n",
    "        rei_scale = 0.0\n",
    "        if p_B_given_A_rei > 0 and p_B_rei > 0:\n",
    "            rei_scale = np.log(p_B_given_A_rei / p_B_rei) / np.log(base)\n",
    "\n",
    "        spectrum[f\"scale_{scale}\"] = rei_scale\n",
    "        avg_rei += rei_scale\n",
    "        n_scales += 1\n",
    "\n",
    "    if n_scales > 0:\n",
    "        avg_rei /= n_scales\n",
    "\n",
    "    return {\n",
    "        'MultiScale_REI_Spectrum': spectrum,\n",
    "        'MultiScale_Avg_REI': avg_rei\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_multi_scale_spectrum(result: dict, pair_name: str = \"A→B\"):\n",
    "    if 'MultiScale_REI_Spectrum' in result and result['MultiScale_REI_Spectrum']:\n",
    "        scales = list(result['MultiScale_REI_Spectrum'].keys())\n",
    "        values = list(result['MultiScale_REI_Spectrum'].values())\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(scales, values, color='teal', alpha=0.7)\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        plt.title(f\"Multi-Scale Entanglement Spectrum ({pair_name})\")\n",
    "        plt.xlabel(\"Wavelet Scale\")\n",
    "        plt.ylabel(\"REI Value\")\n",
    "        plt.ylim(-1.2, 1.2)\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No multi-scale data to plot for {pair_name}.\")\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#                     MAIN MULTI-EVENT FUNCTION\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def entanglement_index_multi(\n",
    "    excel_path: str = DEFAULT_EXCEL_PATH,\n",
    "    conditions: Dict[str, Union[str, float, Callable, None]] = None,\n",
    "    base: float = 2,\n",
    "    bootstrap_ci: bool = True,\n",
    "    n_boot: int = 2000,\n",
    "    ci_level: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    smoothing_alpha: float = 1.0,\n",
    "    weight_type: str = 'sqrt_nA',\n",
    "    decay_lambda: float = 0.95,\n",
    "    alpha_joint: float = 0.5,\n",
    "    alpha_non: float = 1.0,\n",
    "    adaptive_decay: bool = True,\n",
    "    wavelet_scales: List[int] = [1, 2, 4, 8],\n",
    "    wavelet_family: str = 'haar',\n",
    "    lag: int = 1,  # NEW: lag for precursors (default 1 day)\n",
    "    target_event: str = 'Event A'  # NEW: target for future state\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Main multi-event function: loads events, computes pairwise + 3-way interaction.\n",
    "    NEW: Lagged EI (shift non-target events backward by lag relative to target)\n",
    "    NEW: Bootstrap CI and p-value for Original E > 0 (precursor significance)\n",
    "    \"\"\"\n",
    "    if conditions is None:\n",
    "        conditions = {\n",
    "            'Event A': 'above_median',\n",
    "            'Event B': 'above_median',\n",
    "            'Event C': 'None'  # default for optional C\n",
    "        }\n",
    "\n",
    "    events_raw = load_events_from_excel(excel_path)\n",
    "\n",
    "    # Binarize all present events\n",
    "    binary_events = {}\n",
    "    for name in events_raw:\n",
    "        cond = conditions.get(name, 'above_median')\n",
    "        binary_events[name] = define_event_series(events_raw[name], cond).astype(int)  # Force int\n",
    "\n",
    "    # Apply lag if >0: shift non-target events backward (precursors to target)\n",
    "    if lag > 0:\n",
    "        if target_event not in binary_events:\n",
    "            raise ValueError(f\"Target event '{target_event}' not found.\")\n",
    "        for name in binary_events:\n",
    "            if name != target_event:\n",
    "                binary_events[name] = binary_events[name].shift(lag).fillna(0).astype(int)  # Shift backward + fillna + int\n",
    "        print(f\"Lag {lag} applied: Non-target events shifted backward as precursors to {target_event}.\")\n",
    "\n",
    "    # Align lengths after shift\n",
    "    min_len = min(len(s) for s in binary_events.values())\n",
    "    for name in binary_events:\n",
    "        binary_events[name] = binary_events[name][:min_len]\n",
    "\n",
    "    n = min_len\n",
    "    result = {'pairwise': {}, 'multipartite': {}, 'lag_info': f\"Lag {lag} days (precursors to {target_event})\" if lag > 0 else \"No lag (synchronous)\"}\n",
    "\n",
    "    # ─── Compute all pairwise ───────────────────────────────────────────────────\n",
    "    event_names = list(binary_events.keys())\n",
    "    for i in range(len(event_names)):\n",
    "        for j in range(i+1, len(event_names)):\n",
    "            name1, name2 = event_names[i], event_names[j]\n",
    "            A = binary_events[name1]\n",
    "            B = binary_events[name2]\n",
    "            raw_A = events_raw[name1].values[:n]\n",
    "            raw_B = events_raw[name2].values[:n]\n",
    "\n",
    "            pair_key = f\"E({name1} → {name2})\"\n",
    "            pair_result = {}\n",
    "\n",
    "            # Original\n",
    "            p_B = B.mean()\n",
    "            if p_B == 0:\n",
    "                pair_result['error'] = \"P(B) = 0\"\n",
    "            else:\n",
    "                p_B_given_A = B[A == 1].mean() if A.sum() > 0 else 0\n",
    "                ei_original = -np.inf if p_B_given_A == 0 else np.log(p_B_given_A / p_B) / np.log(base)\n",
    "                pair_result.update({\n",
    "                    'Entanglement_Index_Original': ei_original,\n",
    "                    'P(B)': p_B,\n",
    "                    'P(B|A)': p_B_given_A,\n",
    "                    'P(A)': A.mean(),\n",
    "                    'n_samples': n,\n",
    "                    'n_A_occurrences': A.sum(),\n",
    "                    'n_B_occurrences': B.sum(),\n",
    "                    'n_joint_occurrences': (A & B).sum()\n",
    "                })\n",
    "\n",
    "                # Bootstrap CI and p-value for precursor significance (E > 0)\n",
    "                if bootstrap_ci:\n",
    "                    np.random.seed(random_state)\n",
    "                    boot_ei = []\n",
    "                    for _ in range(n_boot):\n",
    "                        idx = np.random.choice(n, n, replace=True)\n",
    "                        A_boot = A.iloc[idx] if isinstance(A, pd.Series) else A[idx]\n",
    "                        B_boot = B.iloc[idx] if isinstance(B, pd.Series) else B[idx]\n",
    "                        p_B_boot = B_boot.mean()\n",
    "                        p_B_given_A_boot = B_boot[A_boot == 1].mean() if A_boot.sum() > 0 else 0\n",
    "                        if p_B_boot > 0 and p_B_given_A_boot > 0:\n",
    "                            boot_ei.append(np.log(p_B_given_A_boot / p_B_boot) / np.log(base))\n",
    "                    \n",
    "                    if len(boot_ei) > 0:\n",
    "                        lower = np.percentile(boot_ei, (1 - ci_level)/2 * 100)\n",
    "                        upper = np.percentile(boot_ei, (1 + ci_level)/2 * 100)\n",
    "                        pair_result['bootstrap_ci_original'] = (lower, upper)\n",
    "                        # p-value: proportion of boot E <= 0 (one-sided for positive precursor)\n",
    "                        p_value = sum(np.array(boot_ei) <= 0) / len(boot_ei)\n",
    "                        pair_result['p_value_positive'] = p_value\n",
    "                        pair_result['precursor_significance'] = \"Significant precursor\" if p_value < 0.05 else \"Not significant\"\n",
    "\n",
    "                # Smoothed\n",
    "                n_AB = (A & B).sum()\n",
    "                p_B_sm = (B.sum() + smoothing_alpha) / (n + 2 * smoothing_alpha)\n",
    "                p_B_given_A_sm = (n_AB + smoothing_alpha) / (A.sum() + 2 * smoothing_alpha) if A.sum() > 0 else smoothing_alpha / (n + 2 * smoothing_alpha)\n",
    "                ei_smoothed = 0.0 if p_B_given_A_sm <= 0 or p_B_sm <= 0 else np.log(p_B_given_A_sm / p_B_sm) / np.log(base)\n",
    "                pair_result['Entanglement_Index_Smoothed'] = ei_smoothed\n",
    "\n",
    "                # Normalized\n",
    "                p_AB = n_AB / n\n",
    "                npmi = 0.0\n",
    "                if p_AB > 0 and np.isfinite(ei_original):\n",
    "                    npmi = ei_original / (-np.log(p_AB) / np.log(base))\n",
    "                pair_result['Entanglement_Index_Normalized'] = npmi\n",
    "\n",
    "                # Weighted\n",
    "                weight = np.sqrt(A.sum() / n) if n > 0 else 0.0\n",
    "                ei_weighted = ei_original * weight if np.isfinite(ei_original) else 0.0\n",
    "                pair_result['Entanglement_Index_Weighted'] = ei_weighted\n",
    "\n",
    "                # Resonant + Adaptive\n",
    "                decay_lambda_used = decay_lambda\n",
    "                adaptive_score = None\n",
    "                if adaptive_decay and n > 20:\n",
    "                    try:\n",
    "                        opt_lambda, opt_score = find_optimal_decay_lambda(\n",
    "                            A.values if isinstance(A, pd.Series) else A,\n",
    "                            B.values if isinstance(B, pd.Series) else B,\n",
    "                            alphas=[alpha_joint, alpha_non],\n",
    "                            base=base\n",
    "                        )\n",
    "                        decay_lambda_used = opt_lambda\n",
    "                        adaptive_score = opt_score\n",
    "                    except Exception as e:\n",
    "                        print(f\"Adaptive failed for {pair_key}: {e}\")\n",
    "\n",
    "                t = np.arange(n)\n",
    "                weights = decay_lambda_used ** (n - 1 - t)\n",
    "                w_sum = weights.sum()\n",
    "                w_A = np.sum(weights * A)\n",
    "                w_B = np.sum(weights * B)\n",
    "                w_AB = np.sum(weights * (A & B))\n",
    "\n",
    "                p_B_rei = (w_B + alpha_joint) / (w_sum + 2 * alpha_joint)\n",
    "                p_B_given_A_rei = (w_AB + alpha_joint) / (w_A + alpha_joint + alpha_non) if w_A > 0 else alpha_joint / (w_sum + 2 * alpha_joint)\n",
    "\n",
    "                rei = 0.0 if p_B_given_A_rei <= 0 or p_B_rei <= 0 else np.log(p_B_given_A_rei / p_B_rei) / np.log(base)\n",
    "\n",
    "                pair_result.update({\n",
    "                    'Resonant_Entanglement_Index': rei,\n",
    "                    'decay_lambda_used': decay_lambda_used,\n",
    "                    'adaptive_decay': adaptive_decay,\n",
    "                    'adaptive_lambda_score': adaptive_score\n",
    "                })\n",
    "\n",
    "                # Symmetric + Synergy\n",
    "                p_A = A.mean()\n",
    "                p_A_given_B = A[B == 1].mean() if B.sum() > 0 else 0\n",
    "                ei_reverse = -np.inf if p_A_given_B == 0 else np.log(p_A_given_B / p_A) / np.log(base)\n",
    "                symmetric_e = (rei + (ei_reverse if np.isfinite(ei_reverse) else 0)) / 2\n",
    "\n",
    "                synergy = symmetric_e\n",
    "                if n > 1:\n",
    "                    lagged_A = A.shift(1).fillna(0).astype(int)\n",
    "                    lagged_A[0] = 0\n",
    "                    p_B_given_laggedA = B[lagged_A == 1].mean() if np.sum(lagged_A == 1) > 0 else p_B\n",
    "                    lagged_cond = 0.0 if p_B_given_laggedA <= 0 or p_B <= 0 else np.log(p_B_given_laggedA / p_B) / np.log(base)\n",
    "                    synergy = symmetric_e - lagged_cond\n",
    "\n",
    "                pair_result['Symmetric_Entanglement_Index'] = symmetric_e\n",
    "                pair_result['Synergy_Resonance'] = synergy\n",
    "\n",
    "                # Kernelized\n",
    "                kernel_rei = 0.0\n",
    "                if n > 10:\n",
    "                    K = rbf_kernel(raw_A.reshape(-1, 1), raw_B.reshape(-1, 1), gamma=1.0)\n",
    "                    p_B_kernel = np.mean(K[A == 1]) if np.sum(A == 1) > 0 else 0\n",
    "                    kernel_rei = np.log(p_B_kernel / p_B) / np.log(base) if p_B_kernel > 0 and p_B > 0 else 0.0\n",
    "                pair_result['Kernelized_REI'] = kernel_rei\n",
    "\n",
    "                # Discord Proxy\n",
    "                classical_corr = np.corrcoef(raw_A, raw_B)[0,1] if n > 1 else 0.0\n",
    "                discord_proxy = rei - classical_corr\n",
    "                pair_result['Discord_Proxy'] = discord_proxy\n",
    "\n",
    "                # Multi-Scale\n",
    "                multi_scale = compute_multi_scale_rei(\n",
    "                    A.values if isinstance(A, pd.Series) else A,\n",
    "                    B.values if isinstance(B, pd.Series) else B,\n",
    "                    scales=wavelet_scales,\n",
    "                    decay_lambda=decay_lambda_used,\n",
    "                    alpha_joint=alpha_joint,\n",
    "                    alpha_non=alpha_non,\n",
    "                    base=base,\n",
    "                    wavelet_family=wavelet_family\n",
    "                )\n",
    "                pair_result.update(multi_scale)\n",
    "\n",
    "            result['pairwise'][pair_key] = pair_result\n",
    "\n",
    "    # ─── Multipartite (3-way) if 3+ events ──────────────────────────────────────\n",
    "    if len(event_names) >= 3:\n",
    "        A = binary_events[event_names[0]]\n",
    "        B = binary_events[event_names[1]]\n",
    "        C = binary_events[event_names[2]]\n",
    "        p_AB = (A & B).mean()\n",
    "        p_AB_given_C = ((A & B) & C).sum() / C.sum() if C.sum() > 0 else 0\n",
    "        ei_ab = result['pairwise'][f\"E({event_names[0]} → {event_names[1]})\"]['Entanglement_Index_Original']\n",
    "        ei_ab_given_c = -np.inf if p_AB_given_C == 0 else np.log(p_AB_given_C / p_AB) / np.log(base) if p_AB > 0 else 0\n",
    "        interaction = ei_ab - ei_ab_given_c if np.isfinite(ei_ab) and np.isfinite(ei_ab_given_c) else 0.0\n",
    "\n",
    "        result['multipartite'] = {\n",
    "            'I(A;B;C)': interaction,\n",
    "            'interpretation': \"Positive = synergy (3-way stronger), Negative = redundancy (C explains A-B link)\"\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#                     PRINT FUNCTION (multi-pair aware)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def print_entanglement_result(result: dict):\n",
    "    print(\"═\" * 100)\n",
    "    print(\"ENTANGLEMENT INDEX RESULTS - Multi-Event Version\")\n",
    "    print(\"═\" * 100)\n",
    "    print(result.get('lag_info', \"No lag (synchronous mode)\"))\n",
    "\n",
    "    def interp(e):\n",
    "        if e > 1.0: return \"Strong positive\"\n",
    "        if e > 0.5: return \"Moderate positive\"\n",
    "        if e > 0.0: return \"Weak positive\"\n",
    "        if e < -1.0: return \"Strong negative (suppression)\"\n",
    "        if e < -0.5: return \"Moderate negative\"\n",
    "        return \"Very weak / negligible\"\n",
    "\n",
    "    for pair, metrics in result['pairwise'].items():\n",
    "        print(f\"\\nPair: {pair}\")\n",
    "        print(f\"  Original E          = {metrics.get('Entanglement_Index_Original', 0):.4f}\")\n",
    "        if 'p_value_positive' in metrics:\n",
    "            p = metrics['p_value_positive']\n",
    "            sig = \" (Significant precursor, p={:.4f})\".format(p) if p < 0.05 else \" (Not significant)\"\n",
    "            print(f\"  Precursor p-value   = {p:.4f}{sig}\")\n",
    "        print(f\"  Resonant E (λ={metrics.get('decay_lambda_used', 0.95):.3f}) = {metrics.get('Resonant_Entanglement_Index', 0):.4f}\")\n",
    "        print(f\"  Symmetric           = {metrics.get('Symmetric_Entanglement_Index', 0):.4f}\")\n",
    "        print(f\"  Synergy Resonance   = {metrics.get('Synergy_Resonance', 0):.4f}\")\n",
    "        print(f\"  Kernelized          = {metrics.get('Kernelized_REI', 0):.4f}\")\n",
    "        print(f\"  Discord Proxy       = {metrics.get('Discord_Proxy', 0):.4f}\")\n",
    "        if 'MultiScale_Avg_REI' in metrics:\n",
    "            print(f\"  Multi-Scale Avg     = {metrics['MultiScale_Avg_REI']:.4f}\")\n",
    "            plot_multi_scale_spectrum(metrics, pair)\n",
    "\n",
    "    if 'multipartite' in result:\n",
    "        print(\"\\nMultipartite Interaction:\")\n",
    "        for key, val in result['multipartite'].items():\n",
    "            print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {val}\")\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#                     MAIN INTERFACE\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "path_input = widgets.Text(\n",
    "    value=DEFAULT_EXCEL_PATH,\n",
    "    placeholder='Enter full Excel path',\n",
    "    description='Excel Path:',\n",
    "    layout=widgets.Layout(width='700px')\n",
    ")\n",
    "\n",
    "a_cond = widgets.Dropdown(\n",
    "    options=['None', 'positive', 'negative', 'nonzero', 'above_mean', 'above_median'],\n",
    "    value='above_median',\n",
    "    description='A Condition:'\n",
    ")\n",
    "\n",
    "b_cond = widgets.Dropdown(\n",
    "    options=['None', 'positive', 'negative', 'nonzero', 'above_mean', 'above_median'],\n",
    "    value='above_median',\n",
    "    description='B Condition:'\n",
    ")\n",
    "\n",
    "c_cond = widgets.Dropdown(\n",
    "    options=['None', 'positive', 'negative', 'nonzero', 'above_mean', 'above_median'],\n",
    "    value='None',\n",
    "    description='C Condition (if present):'\n",
    ")\n",
    "\n",
    "wavelet_dropdown = widgets.Dropdown(\n",
    "    options=['haar', 'db4', 'sym4', 'coif1'],\n",
    "    value='haar',\n",
    "    description='Wavelet Family:'\n",
    ")\n",
    "\n",
    "lag_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Lag (days):',\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "target_dropdown = widgets.Dropdown(\n",
    "    options=['Event A', 'Event B', 'Event C'],\n",
    "    value='Event A',\n",
    "    description='Target Event:'\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(description=\"Load Excel & Compute Indices\", button_style='success')\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        try:\n",
    "            events_raw = load_events_from_excel(path_input.value)\n",
    "            conditions = {\n",
    "                'Event A': a_cond.value if a_cond.value != 'None' else None,\n",
    "                'Event B': b_cond.value if b_cond.value != 'None' else None,\n",
    "                'Event C': c_cond.value if c_cond.value != 'None' else None\n",
    "            }\n",
    "            result = entanglement_index_multi(\n",
    "                excel_path=path_input.value,\n",
    "                conditions=conditions,\n",
    "                wavelet_family=wavelet_dropdown.value,\n",
    "                adaptive_decay=True,\n",
    "                lag=lag_slider.value,\n",
    "                target_event=target_dropdown.value\n",
    "            )\n",
    "            print_entanglement_result(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.Label(\"Enter Excel path, select conditions, wavelet, lag (0 = synchronous, >0 = precursor mode), target event, then click Compute:\"),\n",
    "    path_input,\n",
    "    a_cond,\n",
    "    b_cond,\n",
    "    c_cond,\n",
    "    wavelet_dropdown,\n",
    "    lag_slider,\n",
    "    target_dropdown,\n",
    "    run_button,\n",
    "    output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4a3c6-9164-4bed-a3de-6aedc807ff8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
